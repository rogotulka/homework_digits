{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_split = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.loadtxt('./data/digit/train.csv', delimiter=',', skiprows=1)\n",
    "test = np.loadtxt('./data/digit/test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train[:, 0]\n",
    "# приводим размерность к удобному для обаботки виду\n",
    "train_img = np.resize(train[:, 1:], (train.shape[0], 28, 28))\n",
    "test_img = np.resize(test, (test.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_to(img):\n",
    "    parts = []\n",
    "    parts.append(img[:, 0 : img.shape[2]//2, 0 : img.shape[2]//2])\n",
    "    parts.append(img[:, 0 : img.shape[2]//2, img.shape[2]//2 :])\n",
    "\n",
    "    parts.append(img[:, img.shape[2]//2 : , 0 : img.shape[2]//2])\n",
    "    parts.append(img[:, img.shape[2]//2 :, img.shape[2]//2 :])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_parts = split_to(train_img)\n",
    "test_parts = split_to(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sobel_x = np.zeros_like(train_img)\n",
    "train_sobel_y = np.zeros_like(train_img)\n",
    "for i in range(len(train_img)):\n",
    "    train_sobel_x[i] = cv2.Sobel(train_img[i], cv2.CV_64F, dx=1, dy=0, ksize=3)\n",
    "    train_sobel_y[i] = cv2.Sobel(train_img[i], cv2.CV_64F, dx=0, dy=1, ksize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sobel_x = np.zeros_like(test_img)\n",
    "test_sobel_y = np.zeros_like(test_img)\n",
    "for i in range(len(test_img)):\n",
    "    test_sobel_x[i] = cv2.Sobel(test_img[i], cv2.CV_64F, dx=1, dy=0, ksize=3)\n",
    "    test_sobel_y[i] = cv2.Sobel(test_img[i], cv2.CV_64F, dx=0, dy=1, ksize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_parts_sobel_x = split_to(train_sobel_x)\n",
    "train_parts_sobel_y = split_to(train_sobel_y)\n",
    "test_parts_sobel_x = split_to(test_sobel_x)\n",
    "test_parts_sobel_y = split_to(test_sobel_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_part_len_and_theta(x, y):\n",
    "    return cv2.cartToPolar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cart_polar(parts_sobel_x, parts_sobel_y):\n",
    "    parts = []\n",
    "    for i in range(4):\n",
    "        g, theta = cv2.cartToPolar(parts_sobel_x[i], parts_sobel_y[i])\n",
    "        parts.append((g, theta))\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_part_sobel = get_cart_polar(train_parts_sobel_x, train_parts_sobel_y)\n",
    "test_part_sobel = get_cart_polar(test_parts_sobel_x, test_parts_sobel_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Гистограммы вычисляются с учетом длины вектора градиента\n",
    "def get_part_hist(train_img, train_g, train_theta):\n",
    "    train_hist = np.zeros((len(train_img), 16))\n",
    "    for i in range(len(train_img)):\n",
    "        hist, borders = np.histogram(train_theta[i],\n",
    "                                 bins=16,\n",
    "                                 range=(0., 2. * np.pi),\n",
    "                                 weights=train_g[i])\n",
    "        train_hist[i] = hist\n",
    "    return train_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hist(train_part, train_part_sobel):\n",
    "    parts = []\n",
    "    for i in range(4):\n",
    "        part = get_part_hist(train_part[i], train_part_sobel[i][0], train_part_sobel[i][1])\n",
    "        part = part / (np.linalg.norm(part, axis=1)[:, None] + 1e-26)\n",
    "        parts.append(part)\n",
    "    parts = np.concatenate([parts[0] , parts[1], parts[2], parts[3]], axis = 1 )\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_part_hist = get_hist(train_parts, train_part_sobel)\n",
    "test_part_hist = get_hist(test_parts, test_part_sobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  9.46646041e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           5.63769831e-02,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  9.96751793e-01,   8.05348548e-02,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   3.50265892e-01,   5.21447724e-01],\n",
       "        ..., \n",
       "        [  9.33628089e-02,   0.00000000e+00,   3.64815597e-01, ...,\n",
       "           7.84430289e-01,   4.93914669e-02,   3.22169042e-03],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           3.44904696e-02,   6.92514324e-02,   2.61992709e-02],\n",
       "        [  2.25512691e-01,   3.57233228e-02,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   9.51834488e-02, ...,\n",
       "           0.00000000e+00,   4.74031714e-01,   8.48818927e-01],\n",
       "        [  2.30732046e-01,   3.95358942e-02,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   7.91824320e-01,   1.25796876e-01],\n",
       "        [  2.26224544e-01,   5.11096546e-02,   1.60520085e-01, ...,\n",
       "           7.00969068e-02,   1.16784451e-01,   1.61650071e-01],\n",
       "        ..., \n",
       "        [  4.21207008e-01,   1.15738626e-01,   1.81119832e-01, ...,\n",
       "           1.63146943e-02,   6.86828806e-03,   3.07769353e-01],\n",
       "        [  1.35544868e-01,   8.29923410e-02,   6.06251244e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   1.95376108e-01],\n",
       "        [  1.01537156e-01,   0.00000000e+00,   7.61460956e-02, ...,\n",
       "           2.35491383e-02,   1.59123703e-02,   8.23709364e-02]],\n",
       "\n",
       "       [[  3.81909532e-01,   3.59735197e-01,   4.86480905e-01, ...,\n",
       "           1.83926547e-01,   7.32527295e-01,   2.55591759e-01],\n",
       "        [  1.53934111e-01,   2.79200294e-02,   1.95311525e-01, ...,\n",
       "           4.48144194e-02,   1.27460045e-01,   1.34278129e-01],\n",
       "        [  3.13818148e-01,   2.54083599e-01,   0.00000000e+00, ...,\n",
       "           6.44175459e-04,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  5.95687281e-01,   3.05300345e-01,   3.85689853e-01, ...,\n",
       "           7.55472916e-02,   0.00000000e+00,   2.71161029e-01],\n",
       "        [  2.29451975e-01,   4.85437602e-02,   1.58037588e-01, ...,\n",
       "           2.89897638e-01,   4.57308466e-01,   3.57590435e-01],\n",
       "        [  2.64365077e-01,   1.40953958e-01,   4.99153173e-01, ...,\n",
       "           5.95611352e-02,   5.68964597e-02,   1.07202992e-01]],\n",
       "\n",
       "       ..., \n",
       "       [[  9.21687729e-02,   8.36117675e-02,   1.46363667e-01, ...,\n",
       "           9.95653456e-02,   8.18047010e-03,   1.43672311e-01],\n",
       "        [  9.41163183e-02,   1.69875465e-01,   5.53505684e-03, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   1.52499725e-01,   2.70327345e-01, ...,\n",
       "           8.35466693e-02,   5.27736834e-01,   1.76114440e-01],\n",
       "        ..., \n",
       "        [  9.27410294e-02,   6.21108777e-02,   1.65183527e-02, ...,\n",
       "           1.56035631e-02,   2.11889923e-01,   3.19334598e-01],\n",
       "        [  2.76194161e-01,   5.73619000e-01,   3.72342770e-01, ...,\n",
       "           3.69577030e-01,   1.20734925e-01,   1.54880341e-01],\n",
       "        [  1.79374980e-01,   4.53518832e-02,   1.55934274e-01, ...,\n",
       "           4.29768353e-02,   0.00000000e+00,   9.17555639e-02]],\n",
       "\n",
       "       [[  2.11463236e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   4.53645979e-01,   2.94706183e-02, ...,\n",
       "           3.56174135e-01,   2.63810426e-02,   1.92211340e-01],\n",
       "        [  2.33904125e-01,   1.49697297e-01,   4.12085470e-02, ...,\n",
       "           0.00000000e+00,   2.03288556e-01,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  3.51461101e-01,   8.31577079e-01,   1.15655444e-01, ...,\n",
       "           1.71354919e-01,   8.28451080e-02,   1.65607553e-01],\n",
       "        [  2.65660528e-01,   7.60906430e-01,   1.67166887e-01, ...,\n",
       "           1.06113035e-01,   2.71934671e-01,   5.83407575e-02],\n",
       "        [  1.14865871e-01,   1.88967517e-01,   7.95917225e-02, ...,\n",
       "           1.27329903e-01,   2.06586677e-01,   4.16483619e-02]],\n",
       "\n",
       "       [[  1.29013030e-01,   1.72894912e-01,   1.31335648e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  6.30620774e-01,   4.52701210e-01,   2.18964835e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           9.64365081e-03,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  3.08215220e-01,   3.27773298e-01,   2.30544061e-01, ...,\n",
       "           1.18273480e-01,   1.12629025e-01,   1.41922982e-01],\n",
       "        [  5.58312560e-01,   1.34360637e-01,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   4.14306343e-02,   3.49716352e-01],\n",
       "        [  4.53678819e-01,   1.31887132e-01,   7.13126198e-02, ...,\n",
       "           5.07808856e-02,   7.12490506e-02,   1.77723344e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.resize(train_part_hist[:, 1:], (train_part_hist.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train_part_hist\n",
    "X_test = test_part_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 8, 8, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 8, 8, 1)\n",
    "\n",
    "y_train = np_utils.to_categorical(train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.8272 - acc: 0.7296 - val_loss: 0.2932 - val_acc: 0.9137\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.4368 - acc: 0.8650 - val_loss: 0.2254 - val_acc: 0.9306\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.3679 - acc: 0.8866 - val_loss: 0.2020 - val_acc: 0.9361\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.3327 - acc: 0.8982 - val_loss: 0.1825 - val_acc: 0.9417\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.3029 - acc: 0.9101 - val_loss: 0.1699 - val_acc: 0.9474\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2781 - acc: 0.9169 - val_loss: 0.1593 - val_acc: 0.9507\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2666 - acc: 0.9190 - val_loss: 0.1518 - val_acc: 0.9518\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2520 - acc: 0.9242 - val_loss: 0.1421 - val_acc: 0.9557\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2350 - acc: 0.9284 - val_loss: 0.1410 - val_acc: 0.9553\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2271 - acc: 0.9322 - val_loss: 0.1387 - val_acc: 0.9551\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2223 - acc: 0.9340 - val_loss: 0.1348 - val_acc: 0.9553\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.2107 - acc: 0.9371 - val_loss: 0.1349 - val_acc: 0.9563\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.2022 - acc: 0.9386 - val_loss: 0.1243 - val_acc: 0.9602\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1978 - acc: 0.9409 - val_loss: 0.1196 - val_acc: 0.9608\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1921 - acc: 0.9426 - val_loss: 0.1146 - val_acc: 0.9637\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1898 - acc: 0.9434 - val_loss: 0.1169 - val_acc: 0.9637\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1796 - acc: 0.9461 - val_loss: 0.1170 - val_acc: 0.9622\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1769 - acc: 0.9476 - val_loss: 0.1134 - val_acc: 0.9637\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1703 - acc: 0.9488 - val_loss: 0.1071 - val_acc: 0.9649\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1689 - acc: 0.9500 - val_loss: 0.1062 - val_acc: 0.9670\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1675 - acc: 0.9489 - val_loss: 0.1055 - val_acc: 0.9678\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1581 - acc: 0.9525 - val_loss: 0.1048 - val_acc: 0.9678\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1588 - acc: 0.9516 - val_loss: 0.1059 - val_acc: 0.9671\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1541 - acc: 0.9528 - val_loss: 0.1027 - val_acc: 0.9682\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1472 - acc: 0.9551 - val_loss: 0.1004 - val_acc: 0.9683\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1444 - acc: 0.9562 - val_loss: 0.1012 - val_acc: 0.9677\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1428 - acc: 0.9570 - val_loss: 0.1000 - val_acc: 0.9676\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1451 - acc: 0.9567 - val_loss: 0.0974 - val_acc: 0.9703\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1412 - acc: 0.9577 - val_loss: 0.1022 - val_acc: 0.9686\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1358 - acc: 0.9580 - val_loss: 0.1026 - val_acc: 0.9684\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1341 - acc: 0.9594 - val_loss: 0.1072 - val_acc: 0.9677\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1334 - acc: 0.9582 - val_loss: 0.0998 - val_acc: 0.9699\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1347 - acc: 0.9603 - val_loss: 0.0941 - val_acc: 0.9703\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1252 - acc: 0.9617 - val_loss: 0.0946 - val_acc: 0.9720\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1227 - acc: 0.9629 - val_loss: 0.0970 - val_acc: 0.9709\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1244 - acc: 0.9630 - val_loss: 0.0956 - val_acc: 0.9711\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1214 - acc: 0.9636 - val_loss: 0.0948 - val_acc: 0.9712\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1197 - acc: 0.9637 - val_loss: 0.0921 - val_acc: 0.9708\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1201 - acc: 0.9638 - val_loss: 0.0944 - val_acc: 0.9706\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1182 - acc: 0.9641 - val_loss: 0.0957 - val_acc: 0.9709\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1170 - acc: 0.9659 - val_loss: 0.0924 - val_acc: 0.9716\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1171 - acc: 0.9655 - val_loss: 0.0942 - val_acc: 0.9719\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1125 - acc: 0.9642 - val_loss: 0.0938 - val_acc: 0.9718\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1127 - acc: 0.9664 - val_loss: 0.0977 - val_acc: 0.9691\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1096 - acc: 0.9666 - val_loss: 0.0931 - val_acc: 0.9718\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1106 - acc: 0.9670 - val_loss: 0.0926 - val_acc: 0.9709\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1073 - acc: 0.9684 - val_loss: 0.0972 - val_acc: 0.9718\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1079 - acc: 0.9670 - val_loss: 0.0953 - val_acc: 0.9718\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1096 - acc: 0.9666 - val_loss: 0.0906 - val_acc: 0.9720\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1025 - acc: 0.9679 - val_loss: 0.0906 - val_acc: 0.9712\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1040 - acc: 0.9686 - val_loss: 0.0930 - val_acc: 0.9707\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1009 - acc: 0.9693 - val_loss: 0.0929 - val_acc: 0.9721\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1051 - acc: 0.9683 - val_loss: 0.0961 - val_acc: 0.9702\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1048 - acc: 0.9683 - val_loss: 0.0932 - val_acc: 0.9718\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0996 - acc: 0.9690 - val_loss: 0.0965 - val_acc: 0.9713\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.1013 - acc: 0.9697 - val_loss: 0.0916 - val_acc: 0.9736\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.1012 - acc: 0.9702 - val_loss: 0.0936 - val_acc: 0.9727\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0986 - acc: 0.9706 - val_loss: 0.0952 - val_acc: 0.9722\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0932 - acc: 0.9719 - val_loss: 0.0963 - val_acc: 0.9722\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0951 - acc: 0.9713 - val_loss: 0.0961 - val_acc: 0.9720\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0967 - acc: 0.9702 - val_loss: 0.0927 - val_acc: 0.9730\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0975 - acc: 0.9713 - val_loss: 0.0967 - val_acc: 0.9714\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0961 - acc: 0.9698 - val_loss: 0.0983 - val_acc: 0.9707\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0953 - acc: 0.9721 - val_loss: 0.0951 - val_acc: 0.9710\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0921 - acc: 0.9715 - val_loss: 0.1038 - val_acc: 0.9712\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0916 - acc: 0.9721 - val_loss: 0.1015 - val_acc: 0.9716\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0924 - acc: 0.9721 - val_loss: 0.0894 - val_acc: 0.9722\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0899 - acc: 0.9729 - val_loss: 0.0983 - val_acc: 0.9728\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0927 - acc: 0.9725 - val_loss: 0.0943 - val_acc: 0.9725\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0919 - acc: 0.9722 - val_loss: 0.0949 - val_acc: 0.9718\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0901 - acc: 0.9716 - val_loss: 0.0986 - val_acc: 0.9717\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0881 - acc: 0.9743 - val_loss: 0.0966 - val_acc: 0.9718\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0878 - acc: 0.9728 - val_loss: 0.1112 - val_acc: 0.9697\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0890 - acc: 0.9732 - val_loss: 0.0984 - val_acc: 0.9717\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0852 - acc: 0.9750 - val_loss: 0.0955 - val_acc: 0.9713\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0917 - acc: 0.9727 - val_loss: 0.1038 - val_acc: 0.9712\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0898 - acc: 0.9728 - val_loss: 0.0967 - val_acc: 0.9724\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0865 - acc: 0.9739 - val_loss: 0.0977 - val_acc: 0.9723\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0826 - acc: 0.9745 - val_loss: 0.0963 - val_acc: 0.9731\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0855 - acc: 0.9749 - val_loss: 0.1012 - val_acc: 0.9722\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0868 - acc: 0.9738 - val_loss: 0.1008 - val_acc: 0.9723\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0817 - acc: 0.9750 - val_loss: 0.0995 - val_acc: 0.9717\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0866 - acc: 0.9744 - val_loss: 0.1051 - val_acc: 0.9716\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0847 - acc: 0.9746 - val_loss: 0.0945 - val_acc: 0.9722\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0871 - acc: 0.9747 - val_loss: 0.0975 - val_acc: 0.9732\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0826 - acc: 0.9761 - val_loss: 0.1036 - val_acc: 0.9698\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0845 - acc: 0.9740 - val_loss: 0.1047 - val_acc: 0.9718\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0831 - acc: 0.9743 - val_loss: 0.1044 - val_acc: 0.9719\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0802 - acc: 0.9753 - val_loss: 0.1088 - val_acc: 0.9702\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0831 - acc: 0.9749 - val_loss: 0.0992 - val_acc: 0.9718\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0838 - acc: 0.9743 - val_loss: 0.0983 - val_acc: 0.9723\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0856 - acc: 0.9739 - val_loss: 0.1041 - val_acc: 0.9719\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0817 - acc: 0.9743 - val_loss: 0.1019 - val_acc: 0.9716\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0855 - acc: 0.9754 - val_loss: 0.1028 - val_acc: 0.9712\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0815 - acc: 0.9757 - val_loss: 0.1057 - val_acc: 0.9708\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0817 - acc: 0.9758 - val_loss: 0.1056 - val_acc: 0.9717\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 17s - loss: 0.0816 - acc: 0.9755 - val_loss: 0.1037 - val_acc: 0.9719\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0822 - acc: 0.9752 - val_loss: 0.1084 - val_acc: 0.9693\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0806 - acc: 0.9767 - val_loss: 0.1064 - val_acc: 0.9720\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 16s - loss: 0.0858 - acc: 0.9744 - val_loss: 0.1104 - val_acc: 0.9710\n",
      "Test loss: 0.110438945114\n",
      "Test accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(8, 8, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train[:N_split], y_train[:N_split],\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_train[N_split:], y_train[N_split:]))\n",
    "score = model.evaluate(X_train[N_split:], y_train[N_split:], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submit.txt', 'w') as dst:\n",
    "    dst.write('ImageId,Label\\n')\n",
    "    for i, p in enumerate(pred, 1):\n",
    "        dst.write('%s,%s\\n' % (i, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![alt text](result/res_2_lab.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
